{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor, TrainingArguments, Trainer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from PIL import Image"
   ],
   "id": "d4aeb7f9edb35200",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "image_dir = 'cleaned_data/ISIC_2019_Training_Input_cleaned'\n",
    "labels_csv = 'cleaned_data/ISIC_2019_Training_GroundTruth.csv'\n",
    "metadata_csv = 'cleaned_data/ISIC_2019_Training_Metadata.csv'\n",
    "\n",
    "# Load labels\n",
    "df_labels = pd.read_csv(labels_csv)\n",
    "df_labels.set_index('image', inplace=True)\n",
    "\n",
    "# Label encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_labels = mlb.fit_transform(df_labels.values)\n",
    "label_names = df_labels.columns.tolist()"
   ],
   "id": "db73aadf1e2a894c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, image_dir, df_labels, feature_extractor, df_metadata=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df_labels = df_labels\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.df_metadata = df_metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.df_labels.index[idx]\n",
    "        image_path = os.path.join(self.image_dir, f\"{image_id}.jpg\")\n",
    "        image = default_loader(image_path)\n",
    "\n",
    "        # Image preprocessing\n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze() for k, v in inputs.items()}\n",
    "\n",
    "        # Multi-labels\n",
    "        labels = torch.tensor(self.df_labels.iloc[idx].values.astype(float), dtype=torch.float)\n",
    "\n",
    "        # Optional metadata\n",
    "        if self.df_metadata is not None:\n",
    "            metadata_row = self.df_metadata.loc[image_id].values.astype(float)\n",
    "            metadata_tensor = torch.tensor(metadata_row, dtype=torch.float)\n",
    "            inputs['metadata'] = metadata_tensor\n",
    "\n",
    "        inputs['labels'] = labels\n",
    "        return inputs"
   ],
   "id": "c8886188ac0269d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Optional: Load metadata\n",
    "use_metadata = False\n",
    "df_metadata = pd.read_csv(metadata_csv, index_col='image') if use_metadata else None\n",
    "\n",
    "dataset = ISICDataset(image_dir=image_dir, df_labels=df_labels, feature_extractor=feature_extractor, df_metadata=df_metadata)"
   ],
   "id": "9a4cf28e5e2b61cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=len(label_names),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Hugging Face Trainer expects dict inputs from dataset\n",
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    return {k: torch.stack([d[k] for d in batch]) for k in keys}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=feature_extractor,\n",
    "    data_collator=collate_fn\n",
    ")"
   ],
   "id": "d6192e48bd7cae4"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "823a243e1e316b2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6cc45cb87292e4ae"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
